{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hugging Face Online\n",
        "\n",
        "Los modelos de Hugging Face están disponibles para descargar en local, y algunos incluso permiten realizar inferencias \"online\". \n",
        "Esto es una gran ventaja ya que nos permite crear aplicaciones analíticas sin necesidad de ocupar un gran espacio de disco.\n",
        "\n",
        "Para ello, podemos ver un ejemplo de modelo en este [LINK](https://huggingface.co/docs/api-inference/index)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los modelos se pueden utilizar para diferentes casos de uso (predicción, análisis de sentimiento, resumir, etc.). Algunos ejemplos los vemos a continuación\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3G4SNCPvkaYi"
      },
      "source": [
        "# Predicción del texto faltante"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4XyS8bcElTkm"
      },
      "source": [
        "Model : https://huggingface.co/bert-base-cased?text=Paris+is+the+%5BMASK%5D+of+France. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QBh0fXFIkyY7"
      },
      "outputs": [],
      "source": [
        "# Configuración \n",
        "import requests\n",
        "import json\n",
        "\n",
        "# Crear tu propio API key en Hugging Face es muy sencillo y Gratis!\n",
        "API_KEY = \"TU-API-KEY\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOCM0AKoimAs",
        "outputId": "03a824d0-1d5f-49a0-c818-a37bdcafbc81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'error': 'Model bert-base-cased is currently loading', 'estimated_time': 20.0}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "API_URL = \"https://api-inference.huggingface.co/models/bert-base-cased\"\n",
        "\n",
        "headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\t\n",
        "output = query({\n",
        "\t\"inputs\": \"The answer to the universe is [MASK].\",\n",
        "})\n",
        "\n",
        "output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtyXLDrMiqfX",
        "outputId": "637d672e-0269-4316-fdee-993e91c25f63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'score': 0.0655432865023613,\n",
              "  'token': 10631,\n",
              "  'token_str': 'Superman',\n",
              "  'sequence': 'The strongest super hero is Superman.'},\n",
              " {'score': 0.01948622055351734,\n",
              "  'token': 8622,\n",
              "  'token_str': 'Batman',\n",
              "  'sequence': 'The strongest super hero is Batman.'},\n",
              " {'score': 0.015481239184737206,\n",
              "  'token': 19408,\n",
              "  'token_str': 'Hulk',\n",
              "  'sequence': 'The strongest super hero is Hulk.'},\n",
              " {'score': 0.015316893346607685,\n",
              "  'token': 10670,\n",
              "  'token_str': 'Zero',\n",
              "  'sequence': 'The strongest super hero is Zero.'},\n",
              " {'score': 0.013313977047801018,\n",
              "  'token': 16496,\n",
              "  'token_str': 'Hercules',\n",
              "  'sequence': 'The strongest super hero is Hercules.'}]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output = query({\n",
        "\t\"inputs\": \"The strongest super hero is [MASK].\",\n",
        "})\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nrdvog5pkRmu",
        "outputId": "ce8b4b9a-3703-487e-c781-06cbedb55622"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'score': 0.9953473210334778,\n",
              "  'token': 2364,\n",
              "  'token_str': 'capital',\n",
              "  'sequence': 'Quito is the capital of Ecuador.'},\n",
              " {'score': 0.0013217513915151358,\n",
              "  'token': 6299,\n",
              "  'token_str': 'Capital',\n",
              "  'sequence': 'Quito is the Capital of Ecuador.'},\n",
              " {'score': 0.0003529535897541791,\n",
              "  'token': 1946,\n",
              "  'token_str': 'seat',\n",
              "  'sequence': 'Quito is the seat of Ecuador.'},\n",
              " {'score': 0.00033725282992236316,\n",
              "  'token': 2057,\n",
              "  'token_str': 'center',\n",
              "  'sequence': 'Quito is the center of Ecuador.'},\n",
              " {'score': 0.0002754410379566252,\n",
              "  'token': 1331,\n",
              "  'token_str': 'city',\n",
              "  'sequence': 'Quito is the city of Ecuador.'}]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output = query({\n",
        "\t\"inputs\": \"Quito is the [MASK] of Ecuador.\",\n",
        "})\n",
        "\n",
        "output"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BBYzB3Uqk1nt"
      },
      "source": [
        "# Q&A Basado en contexto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uIIcEiUYlK9K"
      },
      "outputs": [],
      "source": [
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/deepset/roberta-base-squad2\"\n",
        "headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\t\n",
        "def q_a(context: str):\n",
        "  q = input()\n",
        "  return query({\n",
        "\t\"inputs\": {\n",
        "\t\t\"question\": q,\n",
        "\t\t\"context\": context\n",
        "\t},\n",
        "})['answer']\n",
        "\n",
        "context = \"\"\"\n",
        "  Ecuador is the most beautiful country in the world.\n",
        "  Ecuador has beaches, mountains and jungle. \n",
        "  The capital of Ecuador is Quito.\n",
        "  The people in Ecuador are happy and generous.\n",
        "  \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "81AeTI7qn0vZ",
        "outputId": "dcfa51d8-e849-439e-f0f3-7bf7ad71cb56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Ecuador'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q_a(context)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lG3_ecj4qNWu"
      },
      "source": [
        "# Sacar los Embeddings de las palabras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8Sq-t6ykRhj",
        "outputId": "3f616ed4-80a4-4f31-fc66-30df5a57ea90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Huggingface Inference API\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def query(payload):\n",
        "    import requests\n",
        "    API_URL = \"https://api-inference.huggingface.co/pipeline/feature-extraction/clips/mfaq\"\n",
        "    headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
        "    response = requests.post(API_URL, headers=headers, json=payload)\n",
        "    return response.json()\n",
        "\n",
        "def get_embeding(text):\n",
        "    print(\"Using Huggingface Inference API\")\n",
        "    output = query({\n",
        "        \"inputs\": text,\n",
        "        \"options\": {\"wait_for_model\": True}\n",
        "    })\n",
        "    return output\n",
        "\n",
        "embedding = get_embeding(\"Ecuador is the most beautiful country\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPLaHBz4pfki",
        "outputId": "a02492fb-0651-4342-c3fc-9bd12c4610d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.055637046694755554,\n",
              " 0.13247257471084595,\n",
              " -0.009967251680791378,\n",
              " 0.29034724831581116,\n",
              " 0.011160862632095814,\n",
              " -0.030794207006692886,\n",
              " -0.11202432960271835,\n",
              " 0.08252018690109253,\n",
              " -0.37208491563796997,\n",
              " 0.10821767151355743]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding[:10]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "76-jv3VJqe4l"
      },
      "source": [
        "# Resumenes de textos largos "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3syoHqQpffE",
        "outputId": "cd47a071-108a-449e-baf1-880ed8ada782"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Hugging Face is a company that specializes in Natural Language Processing (NLP) Their Inference API allows developers to easily use pre-trained NLP models to perform various NLP tasks such as Named Entity Recognition (NER) and Question Answering (QA)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Replace 'model_name' with the name of the pre-trained summarization model you want to use\n",
        "model_name = 'sshleifer/distilbart-cnn-12-6'\n",
        "\n",
        "# Replace 'text_to_summarize' with the text you want to summarize\n",
        "text_to_summarize = 'Hugging Face is a company that specializes in Natural Language Processing (NLP). Their Inference API allows developers to easily use pre-trained NLP models to perform various NLP tasks such as Named Entity Recognition (NER), Question Answering (QA), and Summarization. In this example, we will use the Hugging Face Inference API to summarize a text.'\n",
        "\n",
        "# Define the API endpoint\n",
        "endpoint = f'https://api-inference.huggingface.co/models/{model_name}'\n",
        "\n",
        "# Set the request headers\n",
        "headers = {\n",
        "    'Authorization': f'Bearer {API_KEY}',\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "\n",
        "# Set the request data\n",
        "data = {\n",
        "    'inputs': text_to_summarize,\n",
        "    'parameters': {\n",
        "        'max_length': 100,\n",
        "        'min_length': 20,\n",
        "        'do_sample': False\n",
        "    }\n",
        "}\n",
        "\n",
        "# Send the request\n",
        "response = requests.post(endpoint, headers=headers, json=data)\n",
        "\n",
        "# Get the summarized text from the response\n",
        "summarized_text = response.json()[0]['summary_text']\n",
        "\n",
        "# Print the summarized text\n",
        "print(summarized_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UE71ktCspfcO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

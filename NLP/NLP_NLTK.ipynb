{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"NLP_NLTK.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"qjBAzmnBIAip","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620808385915,"user_tz":-120,"elapsed":7432,"user":{"displayName":"Patricio Fern√°ndez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheD4MuUAw5Yt4N7L8MrvBJfVhPnf2Fy4H7Ikb8=s64","userId":"06295449891970109251"}},"outputId":"897fece5-670c-4583-dcfb-e8edb43e37f9"},"source":["!pip install -U pyspellchecker\n","!pip install emoji"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: pyspellchecker in /usr/local/lib/python3.7/dist-packages (0.6.2)\n","Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.2.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"i_51sO6IIAiu"},"source":["# Tutorial de NLTK para NLP\n","\n","En este corto tutorial veremos algunas de las herramientas y m√©todos que tiene NLTK para el procesamiento de texto. Tambi√©n nos apoyaremos en la librer√≠a [RE](https://docs.python.org/3/library/re.html) (Expresiones Regulares) para la limpieza del texto. Empezamos creando una lista de Tweets sint√©ticos, ya que lo que nos interesa en este Notebook es la parte del procesamiento. \n"]},{"cell_type":"code","metadata":{"id":"zw37k9PoIAiv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620808385920,"user_tz":-120,"elapsed":7308,"user":{"displayName":"Patricio Fern√°ndez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheD4MuUAw5Yt4N7L8MrvBJfVhPnf2Fy4H7Ikb8=s64","userId":"06295449891970109251"}},"outputId":"61e0040d-c84f-4a42-f38e-3aed61d20bfc"},"source":["import re\n","from nltk.tokenize import word_tokenize, TweetTokenizer # tokenizador\n","from string import punctuation \n","from nltk.corpus import stopwords # elimina palabras de poco valor\n","from nltk.stem.wordnet import WordNetLemmatizer # stemming lemming\n","# Instalamos algunas de las APIs y herramientas de NLTK\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"j3NgMrJ7IAi0"},"source":["# Creamos nuestras stopwords\n","stopwords_ = set(stopwords.words('english') + list(punctuation)+ [\"rt\"]) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BG1nFNfwpnYN"},"source":["Tambi√©n podemos eliminar alguna palabra de la lista de Stopwords. Qu√© pasaba con las negaciones en el caso de uso pasado???"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M6O8X37YpxNd","executionInfo":{"status":"ok","timestamp":1620808435539,"user_tz":-120,"elapsed":847,"user":{"displayName":"Patricio Fern√°ndez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheD4MuUAw5Yt4N7L8MrvBJfVhPnf2Fy4H7Ikb8=s64","userId":"06295449891970109251"}},"outputId":"e0aa97d8-5066-485b-8e66-47373611a663"},"source":["print('Esta la palabra \"no\"? ->','no' in stopwords_)\n","stopwords_.remove('no')\n","print('Y ahora??? ->','no' in stopwords_)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Esta la palabra \"no\"? -> True\n","Y ahora??? -> False\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f_kKDizQIAi3"},"source":["tweets = [\n","    \"Hellooooooo!! WHat's wrong with the world today!!!! @user1 #bored #world\",\n","    \"RT I simply looove this outfit www.fakeoutfitpage.com, it's my favorite. I can't stop thinking about it!! @shopingmall #fashion\",\n","    \"The launch of the @SpaceY has been cancelled, I don't want to believe this :( . #notcool #spacey\",\n","    \"RT Hey! Visit www.thisisafakeurl.com to get a FREEEEE coupon on ALL the @fakeshop productos. #Freecoupon\",\n","    \"What a nice album @hotplay has released, I JUST CAN'T STOP LISTENING TO IT. THE BEEEEEEEEEST!! #hotplay #music\"    \n","    \n","]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Gqv2t7_IAi8"},"source":["### Vamos a trabajar con un Tweet para revisar cada paso, luego creamos una funci√≥n para realizarlo en todo el corpus"]},{"cell_type":"code","metadata":{"id":"c8aNbPMMIAi9","outputId":"c150f12c-a4f5-4b9d-fa10-b0dbbda94943"},"source":["# Vamos a trabajar con un tweet para ir viendo cada paso\n","tweet = tweets[1]\n","tweet"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\" RT I simply looove this outfit www.fakeoutfitpage.com, it's my favorite. I can't stop thinking about it!! @shopingmall #fashion\""]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"uC6_HqI1IAi_","outputId":"cfa32d44-e111-49fa-e1ac-8cae50419770"},"source":["# empezamos transformando a min√∫sculas\n","tweet = tweet.lower()\n","tweet"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\" rt i simply looove this outfit www.fakeoutfitpage.com, it's my favorite. i can't stop thinking about it!! @shopingmall #fashion\""]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"EQ1koVPCIAjC","outputId":"789f10e2-0dbe-4569-9398-5e1c7403eda9"},"source":["# removemos la URL usando expresiones regulares\n","tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', tweet)\n","tweet"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\" rt i simply looove this outfit URL it's my favorite. i can't stop thinking about it!! @shopingmall #fashion\""]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"PJUjpUGyIAjG","outputId":"c4df6020-abf0-4eb6-8c2b-632d944960dd"},"source":["\"@usuario\".replace(\"@\",\"\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'usuario'"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"srb9mbOEIAjJ","outputId":"12cecd46-70a7-4d35-9431-aece85c8995c"},"source":["# removemos el usario expresiones regulares\n","tweet = re.sub('@[^\\s]+', 'USUARIO', tweet)\n","tweet"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\" rt i simply looove this outfit URL it's my favorite. i can't stop thinking about it!! USUARIO #fashion\""]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"ACxEO2OLIAjN","outputId":"fc9a8401-50a4-4aba-ce11-d9fcf78b6886"},"source":["# removemos el hashtag\n","tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n","tweet"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\" rt i simply looove this outfit URL it's my favorite. i can't stop thinking about it!! USUARIO fashion\""]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"P_s7usW0IAjS"},"source":["# Eliminamos la repetici√≥n de caracteres en LOOOOOOOOOOVE\n","tweet = re.sub(r'(.)\\1+', r'\\1\\1', tweet) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wiRaALkCIAjV","outputId":"75f0388d-0d94-4888-a7b7-da3dfa34e943"},"source":["# probamos los tokenizadores que cargamos \n","# word tokenizer \n","print(word_tokenize(tweet)) # remove repeated characters (helloooooooo into hello)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['rt', 'i', 'simply', 'loove', 'this', 'outfit', 'URL', 'it', \"'s\", 'my', 'favorite', '.', 'i', 'ca', \"n't\", 'stop', 'thinking', 'about', 'it', '!', '!', 'USUARIO', 'fashion']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mobgbT1ZIAjb"},"source":["No me gusta mucho el resultado ya que palabras como it's se dividen, igual can't. Probamos el otro"]},{"cell_type":"code","metadata":{"id":"SUZrCwo_IAjc","outputId":"5483964d-a985-46c7-fd7e-be198f36fb65"},"source":["tknzr = TweetTokenizer()\n","print(tknzr.tokenize(tweet))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['rt', 'i', 'simply', 'loove', 'this', 'outfit', 'URL', \"it's\", 'my', 'favorite', '.', 'i', \"can't\", 'stop', 'thinking', 'about', 'it', '!', '!', 'USUARIO', 'fashion']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FYw2d0BEIAjf"},"source":["Este es mejor, y adem√°s est√° dise√±ado para Twitter :). Lo utilizaremos de ahora en adelante "]},{"cell_type":"code","metadata":{"id":"ziextV92IAjf","outputId":"b81f259c-975f-49b8-e6da-e1e6520af42d"},"source":["# TOkenizamos \n","tweet = tknzr.tokenize(tweet)\n","print(tweet)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['rt', 'i', 'simply', 'loove', 'this', 'outfit', 'URL', \"it's\", 'my', 'favorite', '.', 'i', \"can't\", 'stop', 'thinking', 'about', 'it', '!', '!', 'USUARIO', 'fashion']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6DH95d1GIAjh","outputId":"ba9f8435-9e7f-46aa-cd38-441dff3dfb0e"},"source":["# Quitamos las stopwords\n","tweet = [word for word in tweet if word not in stopwords_] # nuestras stopwords\n","print(tweet)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['simply', 'loove', 'outfit', 'URL', 'favorite', \"can't\", 'stop', 'thinking', 'USUARIO', 'fashion']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jzruNxfxIAjj","outputId":"3f3b63c9-aea7-4419-9142-a5c33ae06dad"},"source":["def stem_lemm(tweet_list):\n","    \"\"\"\n","    Lemmatiza un tweeet uitlizando el lematizador de NLTK\n","    :param tweet_list: Un tweet tokenizado previamente\n","    :return: Una lista de tokens\n","    \"\"\"\n","    lem = WordNetLemmatizer()\n","    normalized_tweet = []\n","    for word in tweet_list:\n","        normalized_text = lem.lemmatize(word,'v')\n","        normalized_tweet.append(normalized_text)\n","    return normalized_tweet\n","\n","print(stem_lemm(tweet))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['simply', 'loove', 'outfit', 'URL', 'favorite', \"can't\", 'stop', 'think', 'USUARIO', 'fashion']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"k0Lu_6tTIAjs"},"source":["## Correcci√≥n gramatical \n","\n","En muchos casos tambi√©n es posible que necesitemos a√±adir un corrector gramatical para nuestro proyecto. Eso se puede hacer mediante varias librer√≠as, pero una de las m√°s comunes es SpellChecker\n"]},{"cell_type":"code","metadata":{"id":"bdOkSzJFIAjs","outputId":"ced9d45a-347b-47e8-8e6f-b6a16075a754"},"source":["from spellchecker import SpellChecker\n","\n","spell = SpellChecker()\n","\n","# Encuentra las que tienen errores\n","misspelled = spell.unknown(tweet)\n","\n","for word in misspelled:\n","    # La correci√≥n m√°s probable\n","    print(spell.correction(word))\n","\n","    # otros conadidatos\n","    print(spell.candidates(word))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["love\n","{'love', 'looe', 'loose'}\n","usuario\n","{'usuario'}\n","usl\n","{'curl', 'ural', 'ura', 'uri', 'urn', 'crl', 'usl', 'ucl', 'rl', 'ure', 'urc', 'uhl', 'urd', 'erl', 'hurl', 'purl', 'brl', 'ur', 'ual', 'urr', 'u/l'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yBnq58-0IAjw","outputId":"47fc1dba-3fd5-42b5-d49d-2f3065616c17"},"source":["# Corregimos el tweet. \n","[spell.correction(word) if word in misspelled else word for word in tweet]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['simply',\n"," 'love',\n"," 'outfit',\n"," 'URL',\n"," 'favorite',\n"," \"can't\",\n"," 'stop',\n"," 'thinking',\n"," 'USUARIO',\n"," 'fashion']"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"5tOuPJYDIAjz"},"source":["# Todo junto \n","\n","Ahora que hemos visto y probado varios m√©todos. Podemos hacer una funci√≥n o una clase con todo lo necesario para limpiar nuestros Tweets"]},{"cell_type":"code","metadata":{"id":"hX5HoTShIAj0"},"source":["def limpia_tweets(tweet): \n","    # empezamos transformando a min√∫sculas\n","    clean_tweet = tweet.lower()\n","    # removemos la URL usando expresiones regulares\n","    clean_tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', '', clean_tweet) # ya no reemplazamos por URL, sino por vacio\n","    # Quitamos los usuarios\n","    clean_tweet = re.sub('@[^\\s]+', '', clean_tweet)\n","    # Quitamos hashtag\n","    clean_tweet = re.sub(r'#([^\\s]+)', r'\\1', clean_tweet)\n","    # Eliminamos repetici√≥n de caracteres \n","    clean_tweet = re.sub(r'(.)\\1+', r'\\1\\1', clean_tweet) \n","    # Tokenizamos \n","    clean_tweet = tknzr.tokenize(clean_tweet)\n","    # Quitamos las stopwords\n","    clean_tweet = [word for word in clean_tweet if word not in stopwords_] # nuestras stopwords\n","    # lemming y stemming \n","    clean_tweet = stem_lemm(clean_tweet)\n","    # Encuentra las que tienen errores\n","    misspelled = spell.unknown(clean_tweet)\n","    # Corregimos el tweet. \n","    clean_tweet = [\n","        spell.correction(word) if word in misspelled else word for word in clean_tweet]\n","    return clean_tweet\n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8PCefUo6IAj2","outputId":"b0c435c2-fd75-4cb2-bd64-9cc524b73401"},"source":["print(limpia_tweets(tweets[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['simply', 'love', 'outfit', 'favorite', \"can't\", 'stop', 'think', 'fashion']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e6rp1zxDIAj7"},"source":["# Todos nuestros Tweets\n","tweets_limpios = [limpia_tweets(tweet) for tweet in tweets]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"83iCS-HoIAj_","outputId":"fb5b4e08-42aa-4781-dd42-41fcab452636"},"source":["for t in tweets_limpios:\n","    print(t)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['hello', 'whats', 'wrong', 'world', 'today', 'bore', 'world']\n","['simply', 'love', 'outfit', 'favorite', \"can't\", 'stop', 'think', 'fashion']\n","['launch', 'cancel', 'want', 'believe', 'of', 'notcool', 'spacey']\n","['hey', 'visit', 'get', 'free', 'coupon', 'products', 'freecoupon']\n","['nice', 'album', 'release', \"can't\", 'stop', 'listen', 'best', 'hotly', 'music']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DPA9JTe_IAkB"},"source":["# Emojis!!\n","\n","Para el tratamiento de emojis, comparto dos alternativas. Una es traducirlo (requiere instalar la librer√≠a emoji) o eliminarlos con expresiones regulares."]},{"cell_type":"code","metadata":{"id":"MHM68OFIIAkC","outputId":"33755ef5-1ae6-41c1-bb6f-f4da0be4aa53"},"source":["import emoji #!pip install emoji\n","\n","# Traducimos usando la librer√≠a emoji\n","print(emoji.demojize('Python is üëç'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Python is :thumbs_up:\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ivMFnfiMIAkE","outputId":"718ef805-4ba6-4f16-bb71-e9916165bda4"},"source":["def remove_emoji(string):\n","    \"\"\"\n","    Elimina los emojis de una cadena de texto. \n","    :param string: Una cadena de texto \n","    :return: Una cadena de texto sin los emojis\n","    \n","    \"\"\"\n","    emoji_pattern = re.compile(\"[\"\n","                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","                           u\"\\U00002702-\\U000027B0\"\n","                           u\"\\U000024C2-\\U0001F251\"\n","                           \"]+\", flags=re.UNICODE)\n","    return emoji_pattern.sub(r'', string)\n","\n","print(remove_emoji('Python is üëç'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Python is \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vSSXVqklIAkH"},"source":[""],"execution_count":null,"outputs":[]}]}